# ############################################################################
# Auido Tokenizer: WavLM
# Extraction: Librispeech 960h
# Authors: Jarod Duret 2024
# ############################################################################
# Seed needs to be set at top of yaml, before objects with parameters are made

seed: 1986
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref results/wavlm
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/extraction_log.txt

# Data files
data_folder: !PLACEHOLDER  # e.g., /path/to/LibriSpeech
train_splits: ["train-clean-100"] #, "train-clean-360", "train-other-500"
dev_splits: ["dev-clean"]
test_splits: ["dev-clean", "test-clean", "test-other"]
skip_prep: False
train_csv: !ref <output_folder>/train.csv
valid_csv: !ref <output_folder>/dev-clean.csv
test_csv:
  - !ref <output_folder>/test-clean.csv
  - !ref <output_folder>/test-other.csv

batch_size: 8
num_workers: 8
src_key: wav
id_key: id

# Dataloader options
dataloader_opts:
   batch_size: !ref <batch_size>
   shuffle: True
   num_workers: !ref <num_workers>

### Configuration for  discrete SSL model
# ssl_model_type: hubert, wavlm, wav2vec2
# ssl_hub: facebook/hubert-large-ll60k, microsoft/wavlm-large,  facebook/wav2vec2-large
ssl_model_type: wavml
ssl_hub: microsoft/wavlm-large
ssl_folder: !ref <save_folder>/ssl_checkpoint
kmeans_cache_dir: !ref <save_folder>/kmeans_checkpoint
kmeans_dataset: LibriSpeech
vocoder_repo_id: speechbrain/hifigan-wavlm-k1000-LibriTTS
freeze_ssl: True
freeze_feature_extractor: True
num_clusters: 1000
save_embedding: False

### Config for Tokenizer
# Layer number should be among the supported layers for discrete SSL models(kmenas  model should be available for that layer)
# ssl_layer_num: [3, 7, 12, 23]
# deduplicate: [False, False, False, False]
# bpe_tokenizer_path: [null , null,  null, null]
ssl_layer_num: [1, 3, 7, 12, 18, 23]
num_codebooks: 6
deduplicate: [False, False, False, False, False, False]
bpe_tokenizer_path: [null, null, null, null, null, null]
sample_rate: 16000
encoder_dim: 1024

ssl_model: !new:speechbrain.lobes.models.huggingface_transformers.wavlm.WavLM
   source: !ref <ssl_hub>
   output_norm: False
   freeze: !ref <freeze_ssl>
   freeze_feature_extractor: !ref <freeze_feature_extractor>
   output_all_hiddens: True
   save_path: !ref <ssl_folder>

tokenizer: !new:model.tokenizer_interface.DiscreteSSLTokenizer
   save_path: !ref <kmeans_cache_dir>
   ssl_model: !ref <ssl_model>
   vocoder_repo_id: !ref <vocoder_repo_id>
   kmeans_dataset: !ref <kmeans_dataset>
   num_clusters: !ref <num_clusters>

tokens_extractor: !new:utils.tokens.TokensExtractor
  tokenizer: !ref <tokenizer>
  sample_rate: !ref <sample_rate>
  src_key: !ref <src_key>
  id_key: !ref <id_key>
  dataloader_opts: !ref <dataloader_opts>