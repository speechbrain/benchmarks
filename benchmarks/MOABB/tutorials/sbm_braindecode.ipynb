{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": [
    "JnRSS3jGxVsk",
    "-GhrvkOFT9_t",
    "vxr8nZ7bbP15",
    "kd6sYnYM1Hd6"
   ],
   "toc_visible": true,
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMrZ+XOt2qgiT4tMI4c/k4/"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial no. 3 of SpeechBrain-MOABB: Integrating braindecode models"
   ],
   "metadata": {
    "id": "vSB-QzlYVCYY"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnRSS3jGxVsk"
   },
   "source": [
    "## **Prerequisites**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download SpeechBrain-MOABB\n",
    "\n",
    "SpeechBrain-MOABB can be downloaded from the GitHub repository listed below."
   ],
   "metadata": {
    "id": "-GhrvkOFT9_t"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KSOTkqPsJXxZ"
   },
   "source": [
    "!git clone https://github.com/speechbrain/benchmarks"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxr8nZ7bbP15"
   },
   "source": [
    "### Install SpeechBrain and SpeechBrain-MOABB requirements, and install SpeechBrain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VFEX28mu4dFt"
   },
   "source": [
    "%%capture\n",
    "!pip install speechbrain\n",
    "\n",
    "%cd /content/benchmarks/benchmarks/MOABB\n",
    "!pip install -r extra-requirements.txt # Install additional dependencies\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd6sYnYM1Hd6"
   },
   "source": [
    "### Install braindecode"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BkjIu0hD1Hd9"
   },
   "source": [
    "%%capture\n",
    "!pip install braindecode"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Define the yaml file integrating a braindecode model**\n",
    "\n",
    "Based on the yaml file defined in the tutorial no. 0, let us assume that we are interested into using a model already developed in braindecode library. SpeechBrain-MOABB includes the model class `BraindecodeNN` that transforms a braindecode model for being compliant with SpeechBrain and SpeechBrain-MOABB. Then, the braindecode model can be integrated seamlessly with the usual decoding pipeline of SpeechBrain-MOABB. For example, for using EEGInception model, we can do the following."
   ],
   "metadata": {
    "id": "f45uzf3mUNyc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_hyperparams = \"\"\"\n",
    "# MODEL\n",
    "input_shape: [null, !ref <T>, !ref <C>, null]\n",
    "braindecode_model: !new:braindecode.models.EEGInception\n",
    "    n_outputs: !ref <n_classes>\n",
    "    n_chans: !ref <C>\n",
    "    n_times: !ref <T>\n",
    "    add_log_softmax: True\n",
    "\n",
    "model: !new:models.BraindecodeNN.BraindecodeNN\n",
    "    model: !ref <braindecode_model>\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "IYzVM2gp3fM1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we can add this model hyper-parameters to the other hyper-parameters defining the decoding pipeline."
   ],
   "metadata": {
    "id": "rpoTepu-3oJ7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "example_hyperparams = \"\"\"\n",
    "seed: 1234\n",
    "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "# DIRECTORIES\n",
    "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
    "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
    "output_folder: !PLACEHOLDER #'path/to/results'\n",
    "\n",
    "# DATASET HPARS\n",
    "# Defining the MOABB dataset.\n",
    "dataset: !new:moabb.datasets.BNCI2014001\n",
    "save_prepared_dataset: True # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards\n",
    "data_iterator_name: 'leave-one-session-out'\n",
    "target_subject_idx: 0\n",
    "target_session_idx: 1\n",
    "events_to_load: null # all events will be loaded\n",
    "original_sample_rate: 250 # Original sampling rate provided by dataset authors\n",
    "sample_rate: 125 # Target sampling rate (Hz)\n",
    "# band-pass filtering cut-off frequencies\n",
    "fmin: 1\n",
    "fmax: 40\n",
    "n_classes: 4\n",
    "tmin: 0.\n",
    "tmax: 4.0\n",
    "# number of steps used when selecting adjacent channels from a seed channel (default at Cz)\n",
    "n_steps_channel_selection: 3\n",
    "T: !apply:math.ceil\n",
    "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
    "C: 22\n",
    "test_with: 'best' # 'last' or 'best'\n",
    "test_key: \"acc\" # Possible opts: \"loss\", \"f1\", \"auc\", \"acc\"\n",
    "\n",
    "# METRICS\n",
    "f1: !name:sklearn.metrics.f1_score\n",
    "    average: 'macro'\n",
    "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
    "cm: !name:sklearn.metrics.confusion_matrix\n",
    "metrics:\n",
    "    f1: !ref <f1>\n",
    "    acc: !ref <acc>\n",
    "    cm: !ref <cm>\n",
    "\n",
    "# TRAINING HPARS\n",
    "n_train_examples: 100  # it will be replaced in the train script\n",
    "# checkpoints to average\n",
    "avg_models: 1\n",
    "number_of_epochs: 1000\n",
    "lr: 0.001\n",
    "# Learning rate scheduling (cyclic learning rate is used here)\n",
    "max_lr: !ref <lr> # Upper bound of the cycle (max value of the lr)\n",
    "base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)\n",
    "step_size_multiplier: 5 #from 2 to 8\n",
    "step_size: !apply:round\n",
    "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
    "    base_lr: !ref <base_lr>\n",
    "    max_lr: !ref <max_lr>\n",
    "    step_size: !ref <step_size>\n",
    "label_smoothing: 0.0\n",
    "loss: !name:speechbrain.nnet.losses.nll_loss\n",
    "    label_smoothing: !ref <label_smoothing>\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter  # epoch counter\n",
    "    limit: !ref <number_of_epochs>\n",
    "batch_size: 32\n",
    "valid_ratio: 0.2\n",
    "\n",
    "# DATA NORMALIZATION\n",
    "dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)\n",
    "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
    "    dims: !ref <dims_to_normalize>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example_hyperparams += model_hyperparams"
   ],
   "metadata": {
    "id": "f_m7D3eiUbHC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the yaml file on disk\n",
    "f = open('/content/example_hyperparams.yaml', \"w\")\n",
    "f.write(example_hyperparams)\n",
    "f.close()"
   ],
   "metadata": {
    "id": "DbJcCq8fYgL-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Train the neural network on a single cross-validation fold**\n",
    "\n",
    "Finally, we can train the network as done in tutorial no. 1. For brevity, we override also here the number of training epochs to 50 epochs."
   ],
   "metadata": {
    "id": "qiOA1AlVg48b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train.py /content/example_hyperparams.yaml \\\n",
    "--data_folder '/content/data/BNCI2014001' \\\n",
    "--cached_data_folder '/content/data' \\\n",
    "--output_folder '/content/results/single-fold-example-braindecode/BNCI2014001' \\\n",
    "--data_iterator_name 'leave-one-session-out' \\\n",
    "--target_subject_idx 0 \\\n",
    "--target_session_idx 1 \\\n",
    "--number_of_epochs 50"
   ],
   "metadata": {
    "id": "pYEa8oubbvk-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}